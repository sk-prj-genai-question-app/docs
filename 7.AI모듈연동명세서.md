# AI 모듈 연동 명세서

## 1. 기술 스택

- **AI Framework**: LangChain
- **API 서버**: FastAPI/Uvicorn(문제 생성)
- **Vector DB**: FAISS-CPU
- **LLM**: Google Gemini(문제 생성), OpenAI GPT(챗봇)
- **Embeddings**: Google Generative AI Embeddings(문제 생성), OpenAI Embeddings(챗봇)
- **기타 주요 라이브러리**:
    - python-dotenv: 환경 변수를 .env 파일에서 로드
    - unstructured: 다양한 문서 형식에서 텍스트 추출
    - python-magic: 파일 유형 감지
    - python-docx: DOCX 파일 처리
     - tiktoken: OpenAI 모델 토큰화
    - sentence_transformers: 문장 임베딩 생성

## 2. 프로젝트 구조

```
ai-service/
├── app/                        # FastAPI 서버
│   ├── chatbot/                # 사용자 맞춤 챗봇
│   │   ├── models/             # 챗봇 모델
│   │   ├── routes/             # 챗봇 라우터
│   │   ├── services/           # 챗봇 서비스
│   │   └── utils/              # 챗봇 유틸리티
│   ├── problem_generator/      # 문제 생성
│   ├── user_question_chatbot   # 문제 별 사용자 질문 챗봇
│   └── main.py                 # 메인 애플리케이션
├── data/                       # 학습용 data와 스크래핑 코드
│   ├── article_data/           # 주제 학습용 기사 data
│   └── jlpt_data/              # 문제 학습용 예제 data
├── faiss_index/                # Vector DB
├── faiss_index_chatbot/        # 챗봇 Vector DB
├── Dockerfile
├── README.md
└── requirements.txt
```

## 3. 환경 설정

```env
# 문제 생성 모델(gemini-1.5-pro-latest) 활용을 위한 API KEY
GOOGLE_API_KEY=

# OPENAI_API_KEY 에러 발생시
GROQ_API_KEY=

# 챗봇 모델(gpt-4o-mini) 활용을 위한 API KEY
OPENAI_API_KEY=
```

## 4. 주요 API

### 4.1 문제 생성 API

- **POST** `/problems/generate`
  JLPT 레벨과 문제 유형을 기반으로 LangChain RAG 체인을 활용해 문제를 생성하고, 백엔드로 전송하여 저장합니다.

### 4.2 사용자 맞춤 챗봇 API

- **POST** `/chatbot`
  사용자의 질문의 키워드를 분석하여, 적절한 LangChain 체인을 선택하여 문제를 생성하거나 AI 응답을 응답을 제공합니다. 

### 4.3 문제 별 사용자 질문 챗봇 API

- **POST** `/user_question_chatbot/ask`
  특정 문제와 관련된 질문에 대해 RAG 기반 컨텍스트를 활용하여 AI 응답을 제공합니다.

## 5. RAG 시스템

## 5. RAG 시스템

### 5.1 데이터 처리 파이프라인

1. **파일 로드**: `TextLoader`, `UnstructuredMarkdownLoader`,`DirectoryLoader`
2. **텍스트 분할**: `MarkdownHeaderTextSplitter`+`RecursiveCharacterTextSplitter`(1000자, 200자 오버랩)
3. **임베딩 생성**:
   - 문제 생성용 → `GoogleGenerativeAIEmbeddings` (Gemini 모델)
   - 챗봇용 → `OpenAIEmbeddings` (text-embedding-3-small, 1536차원)
4. **벡터 저장**: `FAISS` (IndexFlatL2)



### 5.2 문제 생성 과정 (`/problems/generate`)

1. **JSON 요구사항 임베딩**: JLPT 레벨, 문제 유형
2. **쿼리 구성**: LangChain PromptTemplate로 문제 요청 문장 생성
3. **문서 검색**: FAISS에서 유사 문서 top-k 검색
4. **LLM 응답**: Gemini 모델이 문제 JSON 생성
5. **후처리**: JSON 파싱 및 검증 → 백엔드 저장 요청

### 5.3 사용자 맞춤 챗봇 (`/chatbot`)

1. **사용자 질문 임베딩**: 사용자 질문 + 이전 대화 내역
2. **체인 선택**: 질문 유형에 따라 적절한 QA 체인 선택
3. **문서 검색**: FAISS에서 유사 컨텍스트 검색
4. **LLM 응답**: OpenAI GPT-4o-mini가 응답 생성
5. 
6. **출력**: 응답과 함께 대화 히스토리 업데이트

### 5.4 문제별 질문 챗봇 (`/user_question_chatbot/ask`)

1. **사용자 질문 임베딩**: 사용자 질문 + 문제 정보
2. **문서 검색**: 해당 문제 기반 관련 문서 검색
3. **LLM 응답**: GPT 모델이 문제에 대한 질문 상세 설명 생성
4. **출력**: 응답과 함께 대화 히스토리 업데이트


## 6. 벡터 DB 설정

- **FAISS 인덱스**: IndexFlatL2
- **임베딩 모델**: GoogleGenerativeAIEmbeddings(문제 생성), OpenAIEmbeddings(챗봇)
- **청크 크기**: 1000자
- **오버랩**: 200자

## 7. Backend 연동

### 7.1 HTTP 통신
- **Spring Boot (백엔드) → 문제 생성 서비스 요청 예시**
```http

POST http://ai-service:8000/problems/generate
Content-Type: application/json

{
  "level": "N2",
  "problem_type": "G"
}

```
- **문제 생성 서비스 서비스 → Spring Boot 응답 예시**
```json

{
  "success": true,
  "code": 200,
  "data": {
    "id": 123,
    "level": "N2",
    "problemType": "G",
    "problemTitleParent": "文法問題",
    "problemTitleChild": "次の文法問題を解いてください。",
    "problemContent": null,
    "choices": [
      { "id": 1, "number": 1, "content": "選択肢1", "isCorrect": false },
      { "id": 2, "number": 2, "content": "選択肢2", "isCorrect": true },
      { "id": 3, "number": 3, "content": "選択肢3", "isCorrect": false },
      { "id": 4, "number": 4, "content": "選択肢4", "isCorrect": false }
    ],
    "answerNumber": 2,
    "explanation": "この文法は〜の意味です。",
    "createdAt": "2025-07-13T10:00:00Z",
    "updatedAt": "2025-07-13T10:00:00Z"
  },
  "message": "문제 생성 성공",
  "timestamp": "2025-07-13T10:00:01Z",
  "requestId": "abcd-1234-efgh-5678"
}

```
---
- **Spring Boot → AI 챗봇 요청 예시**
```http
POST http://ai-service:8000/chatbot
Content-Type: application/json

{
  "user_id": "user123",
  "question": "JLPT N2 문법 문제를 알려줘"
}

```

- **AI 챗봇 일반 질문 응답 서비스 → Spring Boot 응답 예시**
```json
{
    "is_problem": false,
    "answer": "배고파는 일본어로 \"お腹が空いた\" (おなかがすいた)라고 말합니다."
}
```

- **AI 챗봇 문제 생성 서비스 → Spring Boot 응답 예시**
```http
{
    "success": true,
    "code": 200,
    "data": {
        "is_problem": true,
        "level": "N2",
        "problem_type": "G",
        "problem_title_parent": "文法問題",
        "problem_title_child": "適切な助詞を選びましょう",
        "problem_content": "次の文に入る適切な助詞を選んでください。",
        "choices": [
            {
                "number": 1,
                "content": "が"
            },
            {
                "number": 2,
                "content": "を"
            },
            {
                "number": 3,
                "content": "に"
            },
            {
                "number": 4,
                "content": "と"
            }
        ],
        "answer_number": 2,
        "explanation": "この文は、動作の対象を示す助詞を求めています。「を」は、動詞の目的語を示す助詞であり、文脈に最も適しています。他の選択肢は、主語や場所、共に行動する相手を示す助詞ですが、文の意味には合いません。"
    },
    "message": "요청이 성공적으로 처리되었습니다.",
    "timestamp": "2025-07-10T14:08:04.2638483",
    "requestId": "18b3a4a2-744e-4bd2-aa4d-3c7cef7e5b49"
}

```

- **AI 챗봇 문제 생성 서비스 → Spring Boot 응답 예시**
```http

POST http://backend:8080/ai/problem-submit
Content-Type: application/json

문제 및 답안 저장 완료
```

---
- **Spring Boot → 문제별 사용자 질문 챗봇 요청 예시**
```http

POST http://ai-service:8000/user_question_chatbot/ask
Content-Type: application/json

{
  "user_question_id": 123,
  "question": "이 문제에 대해 더 설명해 줄 수 있나요?",
  "chat_history": [
    {"role": "user", "content": "안녕하세요."},
    {"role": "ai", "content": "안녕하세요! 무엇을 도와드릴까요?"}
  ],
  "problem_id": 456,
  "problem_level": "N3",
  "problem_type": "Vocabulary",
  "problem_title_parent": "語彙",
  "problem_title_child": "次の文の（　　）に入れるのに最もよいものを、１・２・３・４から一つ選びなさい。",
  "problem_content": null,
  "problem_choices": [
    {"id": 1, "number": 1, "content": "選択肢１", "is_correct": false},
    {"id": 2, "number": 2, "content": "選択肢２", "is_correct": true},
    {"id": 3, "number": 3, "content": "選択肢３", "is_correct": false},
    {"id": 4, "number": 4, "content": "選択肢４", "is_correct": false}
  ],
  "problem_answer_number": 2,
  "problem_explanation": "選択肢２が正解です..."
}

```
- **AI 문제별 질문 챗봇 → Spring Boot 응답 예시**
```json

{
  "response": "AI의 응답 메시지입니다."
}

```
### 7.2 에러 처리
AI 모듈은 요청 처리 중 다양한 예외 상황에 대해 명확한 응답을 반환합니다. 백엔드는 이를 기반으로 사용자에게 적절한 메시지를 전달합니다.
| 예외 유형            | 발생 상황 예시                                | 응답 예시                       |
| ---------------- | --------------------------------------- | --------------------------- |
| **체인 선택 오류**     | 적절한 RAG 체인을 선택하지 못한 경우                  | `400 Bad Request`           |
| **LLM 응답 형식 오류** | 반환된 JSON이 구조적으로 잘못되었거나 키가 누락된 경우        | `500 Internal Server Error` |
| **백엔드 통신 오류**    | 문제 생성 결과를 백엔드로 전송할 때 네트워크 또는 HTTP 오류 발생 | `500 Internal Server Error`      |
| **타입 오류**        | LLM 응답이 예상한 타입과 다를 때                    | `500 Internal Server Error` |

## 8. 지원 파일 형식
- **형식**: markdown
- **라이브러리**: langchain_community.document_loaders.TextLoader, langchain_community.document_loaders.UnstructuredMarkdownLoader


## 9. 테스트

### 9.1 단위 테스트
- 문서 처리 기능 테스트 (텍스트 분할, 임베딩 생성 등)
- 벡터 검색 정확도 테스트 (FAISS 유사도 검색 검증)
- FastAPI API 엔드포인트 테스트 (`/problems/generate`, `/chatbot`, `/ask`)

### 9.2 API 테스트
- Backend와 AI 모듈 간 HTTP 통신 테스트
- 전체 RAG 파이프라인 (질문 → 문서 검색 → 문제 생성/챗봇 응답) 테스트

## 10. 배포

### 10.1 Docker 컨테이너
```dockerfile

# 1. 베이스 이미지
FROM python:3.12-slim

# 2. 작업 디렉토리
WORKDIR /app

# 3. 실시간 로그 출력 설정
ENV PYTHONUNBUFFERED=1

# 4. 의존성 설치
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# 5. 소스 및 데이터 복사
COPY ./app ./app
COPY ./faiss_index ./faiss_index
COPY ./faiss_index_chatbot ./faiss_index_chatbot

# 6. 포트 노출
EXPOSE 8000

# 7. 비루트 사용자 실행
RUN useradd --create-home appuser
USER appuser

# 8. 앱 실행
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]

```
### 10.2 헬스체크
```
@app.get("/", summary="서버 상태 확인")
def read_root():
    return {"status": "JLPT AI Service is running"}
```